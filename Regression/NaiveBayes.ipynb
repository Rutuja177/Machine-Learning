{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ba6b371",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.geeksforgeeks.org/naive-bayes-classifiers\n",
    "#https://www.geeksforgeeks.org/ml-naive-bayes-scratch-implementation-using-python/?ref=lbp\n",
    "#https://towardsdatascience.com/implementing-naive-bayes-from-scratch-df5572e042ac\n",
    "#https://machinelearningmastery.com/naive-bayes-classifier-scratch-python/#:~:text=Naive%20Bayes%20is%20a%20classification,to%20make%20their%20calculations%20tractable.\n",
    "#to import the dataset\n",
    "from sklearn import datasets\n",
    "from sklearn.datasets import fetch_openml\n",
    "#split the data set\n",
    "from sklearn.model_selection import train_test_split\n",
    "#to create the combination\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af063169",
   "metadata": {},
   "source": [
    "Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbcc46fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1734e5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f4cd94b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ad307e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((135, 4), (135,), (15, 4), (15,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.1, random_state=1)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312e15d2",
   "metadata": {},
   "source": [
    "Training the model on Traning dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e098206",
   "metadata": {},
   "outputs": [],
   "source": [
    "class naiveBayes:\n",
    "    def fit(self, X, y):\n",
    "        self.sample_rows, self.sample_feature  = X.shape\n",
    "        self.sample_class = len(np.unique(y))\n",
    "        \n",
    "        \n",
    "        self.mean = np.zeros((self.sample_class, self.sample_feature))\n",
    "        self.var = np.zeros((self.sample_class, self.sample_feature))\n",
    "        self.priors = np.zeros(self.sample_class)\n",
    "        \n",
    "        for i in range(self.sample_class):\n",
    "            # create a subset of data for the specific class 'c'\n",
    "            X_class = X[y == i]\n",
    "            #calculate means variance and prior\n",
    "            self.mean[i, :] = np.mean(X_class, axis=0)\n",
    "            self.var[i, :] = np.var(X_class, axis=0)\n",
    "            self.priors[i] = X_class.shape[0] / self.sample_rows\n",
    "    \n",
    "    def guassianDenisty(self, x, mean, var):\n",
    "        constant = 1 / np.sqrt(var * 2 * np.pi)\n",
    "        probability = np.exp(-0.5 * ((x - mean) ** 2 / var))\n",
    "        return constant * probability\n",
    "   \n",
    "    def classProbability(self, x):\n",
    "        post = list()\n",
    "\n",
    "        for i in range(self.sample_class):\n",
    "            mean = self.mean[i]\n",
    "            var = self.var[i]\n",
    "            prior = np.log(self.priors[i])\n",
    "            \n",
    "            # calculate new posterior & append to list\n",
    "            post1 = np.sum(np.log(self.guassianDenisty(x, mean, var)))\n",
    "            post1 = prior + post1\n",
    "            post.append(post1)\n",
    "        \n",
    "        # return the index with the highest class probability\n",
    "        return np.argmax(post)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_pred = [self.classProbability(x) for x in X]\n",
    "        return np.array(y_pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "169cf8a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 1.0\n"
     ]
    }
   ],
   "source": [
    "nb = naiveBayes()\n",
    "nb.fit(X_train, y_train)\n",
    "y_prediction = nb.predict(X_test)\n",
    "#print(prediction)\n",
    "#nb.getAccuracy(y_test, prediction)\n",
    "\n",
    "def getAccuracy(y_new, y_p):\n",
    "    return np.sum(y_new==y_p) / len(y_new)\n",
    "\n",
    "print(\"Accuracy is:\",getAccuracy(y_test,y_prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd1b4ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20efbec4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
