{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "XjvTlDM84ADp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as grid\n",
        "from mlxtend.plotting.decision_regions import plot_decision_regions\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import LinearSVC\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "S9BX2dh64GsO"
      },
      "outputs": [],
      "source": [
        "def linear_kernel(x1, x2):\n",
        "  return x1.T @ x2\n",
        "\n",
        "def poly_kernel(x1, x2, d = 2):\n",
        "  #return (1 + np.dot(x1, x2)) ** d\n",
        "  return (1 + x1 @ x2.T) ** d\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29L2kAJV4J6o"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "goLo3GpC4O6u"
      },
      "outputs": [],
      "source": [
        "class svm():\n",
        "    def __init__(self, kernel='linear', c=1.0, tol=1e-3, maxiter=1000):\n",
        "        self._kernel = kernel\n",
        "        self._tol = tol\n",
        "        self._maxiter = maxiter\n",
        "        self._eps = 0.001\n",
        "        \n",
        "        if self._kernel == 'linear':\n",
        "            self._k = linear_kernel\n",
        "        elif self._kernel == 'poly':\n",
        "            self._k = poly_kernel\n",
        "    \n",
        "        self._c = c\n",
        "        \n",
        "    def _init_params(self):\n",
        "        self._error_cache = np.zeros(self._data.shape[0])\n",
        "        self._alphas = np.ones(self._data.shape[0]) * .1\n",
        "        self._b = 0\n",
        "        \n",
        "        if self._kernel == 'linear':\n",
        "            self._weights = np.random.rand(self._data.shape[1])\n",
        "\n",
        "    def predict_score(self, x):\n",
        "        \"\"\"Predicts a raw score (not classification)\n",
        "        \n",
        "        Arguments\n",
        "            x, array (batch_size, n_features) - input samples.\n",
        "        \"\"\"\n",
        "        u = 0\n",
        "        if self._kernel == 'linear':\n",
        "            u = self._weights @ x.T - self._b \n",
        "        else:\n",
        "            for i in range(self._data.shape[0]):\n",
        "                u += self._targets[i] * self._alphas[i] * self._k(self._data[i], x)\n",
        "            u -= self._b\n",
        "        return u\n",
        "        \n",
        "    def predict(self, x):\n",
        "        \"\"\"Classifies input samples.\n",
        "        \n",
        "        Arguments\n",
        "            x, array (batch_size, n_features) - input samples.\n",
        "        \"\"\"\n",
        "        score = self.predict_score(x)\n",
        "\n",
        "        if type(score) is np.ndarray:\n",
        "            score[score < 0] = -1\n",
        "            score[score >= 0] = 1\n",
        "\n",
        "            return score\n",
        "        else:\n",
        "            return -1 if score < 0 else 1\n",
        "\n",
        "    def smo_step(self, i1, i2):\n",
        "        if i1 == i2:\n",
        "            return 0\n",
        "\n",
        "        x1 = self._data[i1]\n",
        "        x2 = self._data[i2]\n",
        "        y1 = self._targets[i1]\n",
        "        y2 = self._targets[i2]\n",
        "        alpha1 = self._alphas[i1]\n",
        "        alpha2 = self._alphas[i2]\n",
        "\n",
        "        # Compute errors for x1 and x2\n",
        "        e1 = self.predict_score(x1) - y1\n",
        "        e2 = self.predict_score(x2) - y2\n",
        "\n",
        "        s = y1 * y2\n",
        "\n",
        "        if s == 1:\n",
        "            L = max(0, alpha2 + alpha1 - self._c)\n",
        "            H = min(self._c, alpha2 + alpha1)\n",
        "        else:\n",
        "            L = max(0, alpha2 - alpha1)\n",
        "            H = min(self._c, self._c + alpha2 - alpha1)\n",
        "\n",
        "        if L == H:\n",
        "            return 0\n",
        "\n",
        "        k11 = self._k(x1, x1)\n",
        "        k22 = self._k(x2, x2)\n",
        "        k12 = self._k(x1, x2)\n",
        "\n",
        "        eta = k11 + k22 - 2 * k12\n",
        "\n",
        "        if eta > 0:\n",
        "            a2 = alpha2 + y2 * (e1 - e2) / eta\n",
        "            if a2 <= L:\n",
        "                a2 = L\n",
        "            elif a2 >= H:\n",
        "                a2 = H\n",
        "        # TODO: the negative case\n",
        "        elif eta < 0:\n",
        "          #Lobj = objective function at a2=L\n",
        "          #Hobj = objective function at a2=H\n",
        "          #if (Lobj < Hobj-eps):\n",
        "            #a2 = L\n",
        "          #else if (Lobj > Hobj+eps):\n",
        "            #a2 = H\n",
        "          #else:\n",
        "            #a2 = alpha2\n",
        "            b = self._b\n",
        "            L1 = alpha1 + s*(alpha2 - L)\n",
        "            H1 = alpha1 + s*(alpha2 - H)\n",
        "\n",
        "            f1 = y1 * (e1 + b) - alpha1 * self._k(i1, i1) - s * alpha2 * self._k(i1, i2)\n",
        "            f2 = y2 * (e2 + b) - alpha2 * self._k(i2, i2) - s * alpha1 * self._k(i1, i2)\n",
        "            ol = (\n",
        "                L1 * f1\n",
        "                + L * f2\n",
        "                + 1 / 2 * L1**2 * self._k(i1, i1)\n",
        "                + 1 / 2 * L**2 * self._k(i2, i2)\n",
        "                + s * L * L1 * self._k(i1, i2)\n",
        "            )\n",
        "            oh = (\n",
        "                H1 * f1\n",
        "                + H * f2\n",
        "                + 1 / 2 * H1**2 * self._k(i1, i1)\n",
        "                + 1 / 2 * H**2 * self._k(i2, i2)\n",
        "                + s * H * H1 * self._k(i1, i2)\n",
        "            )\n",
        "            if ol < (oh - self._eps):\n",
        "              a2 = L\n",
        "            elif ol > oh + self._eps:\n",
        "              a2 = H\n",
        "            else:\n",
        "              a2 = alpha2\n",
        "\n",
        "\n",
        "\n",
        "        else:\n",
        "            print(f\"[DEBUG] smo_step: eta = {eta}\")\n",
        "            \n",
        "        if np.abs(a2 - alpha2) < 1e-3 * (a2 + alpha2 + 1e-3):\n",
        "            return 0\n",
        "\n",
        "        a1 = alpha1 + s * (alpha2 - a2)\n",
        "\n",
        "        # Update threshold to reflect change in Lagrange multipliers\n",
        "        b1 = e1 + y1 * (a1 - alpha1) * k11 + y2 * (a2 - alpha2) * k12 + self._b\n",
        "        b2 = e2 + y1 * (a1 - alpha1) * k12 + y2 * (a2 - alpha2) * k22 + self._b\n",
        "        self._b = (b1 + b2) / 2\n",
        "\n",
        "        # Update weight vector to reflect change in a1 & a2, if SVM is linear\n",
        "        if self._kernel == 'linear':\n",
        "            self._weights = np.sum((self._targets * self._alphas)[:, None] * self._data, axis=0)\n",
        "        else:\n",
        "            self._weights = np.sum((self._targets * self._alphas)[:, None] * self._data, axis=0)\n",
        "        \n",
        "        # Store a1 and a2 in alpha array\n",
        "        self._alphas[i1] = a1\n",
        "        self._alphas[i2] = a2\n",
        "\n",
        "        # update error cache using new multipliers\n",
        "        for i in range (self._data.shape[0]):\n",
        "            self._error_cache[i] = self.predict_score(self._data[i]) - self._targets[i]\n",
        "\n",
        "        return 1\n",
        "\n",
        "    def examine(self, i2):\n",
        "        x2 = self._data[i2]\n",
        "        y2 = self._targets[i2]\n",
        "        alpha2 = self._alphas[i2]\n",
        "        e2 = self.predict_score(x2) - y2\n",
        "        r2 = e2 * y2\n",
        "\n",
        "        # Heuristic for picking the first multiplier\n",
        "        if (r2 < -self._tol and alpha2 < self._c) or (r2 > self._tol and alpha2 > 0):\n",
        "            f_idxs = np.where((self._alphas != 0) & (self._alphas != self._c))[0]\n",
        "\n",
        "            if len(f_idxs) > 1:\n",
        "                # Hueristic for second multiplier: get i1 with lowest absolute error |e1 - e2|\n",
        "\n",
        "                # TODO: Clean this up\n",
        "                if e2 > 0:\n",
        "                    min_error = 999999\n",
        "                    for i, v in enumerate(f_idxs):\n",
        "                        if v == i2:\n",
        "                            continue\n",
        "\n",
        "                        if self._error_cache[v] == 0:\n",
        "                            self._error_cache[v] = self.predict_score(self._data[v]) - self._targets[v]\n",
        "                        error = np.abs(e2 - self._error_cache[v])\n",
        "\n",
        "                        if error < min_error:\n",
        "                            min_error = error\n",
        "                            i1 = v\n",
        "                else:\n",
        "                    max_error = -999999\n",
        "                    for i, v in enumerate(f_idxs):\n",
        "                        if v == i2:\n",
        "                            continue\n",
        "\n",
        "                        if self._error_cache[v] == 0:\n",
        "                            self._error_cache[v] = self.predict_score(self._data[v]) - self._targets[v]\n",
        "                        error = np.abs(e2 - self._error_cache[v])\n",
        "\n",
        "                        if error > max_error:\n",
        "                            max_error = error\n",
        "                            i1 = v\n",
        "\n",
        "                if self.smo_step(i1, i2):\n",
        "                    return 1\n",
        "                \n",
        "                # Loop over all non-zero and non-C alpha, starting at random point\n",
        "                for i, v in enumerate(np.random.permutation(f_idxs)):\n",
        "                    if self.smo_step(v, i2):\n",
        "                        return 1\n",
        "                \n",
        "                # Loop over all possible i1, starting at a random point\n",
        "                for i in range(self._data.shape[0]):\n",
        "                    if i == i2:\n",
        "                        continue\n",
        "                    if self.smo_step(i, i2):\n",
        "                        return 1\n",
        "                \n",
        "        return 0\n",
        "    \n",
        "    def fit(self, data, targets):\n",
        "        self._data = data\n",
        "        self._targets = targets\n",
        "        \n",
        "        self._init_params()\n",
        "        \n",
        "        n_changed = 0\n",
        "        examine_all = True\n",
        "        n_iter = 0\n",
        "        \n",
        "        while (n_changed > 0 or examine_all is True) and n_iter < self._maxiter:\n",
        "            n_changed = 0\n",
        "            n_iter += 1\n",
        "            \n",
        "            if examine_all is True:\n",
        "                # loop over all training examples\n",
        "                for i in range(data.shape[0]):\n",
        "                    n_changed += self.examine(i)\n",
        "            else:\n",
        "                # loop over examples where alpha is not 0 & not C\n",
        "                f_idxs = np.where((self._alphas != 0) & (self._alphas != self._c))[0]\n",
        "                for i, v in enumerate(f_idxs):\n",
        "                    n_changed += self.examine(v)\n",
        "            \n",
        "            if examine_all is True:\n",
        "                examine_all = False\n",
        "            elif n_changed == 0:\n",
        "                examine_all = True"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load iris dataset and split\n"
      ],
      "metadata": {
        "id": "-vIn94A0wX26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iris = datasets.load_iris()\n",
        "X = iris.data[:, :2]\n",
        "y = iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8,random_state = 0)\n"
      ],
      "metadata": {
        "id": "MPNgrwaXtj1N"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using sklearn with Poly kernel"
      ],
      "metadata": {
        "id": "X1Ob650ewnCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting the model with training data\n",
        "\n",
        "poly = OneVsRestClassifier(svm.SVC(kernel='poly', degree=3, C=1))\n",
        "\n",
        "poly.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Making a prediction on the test set\n",
        "prediction = poly.predict(X_test)\n",
        "   \n",
        "# Evaluating the model\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, prediction))\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGuYSRki2OV7",
        "outputId": "ca2a0d97-0721-46e8-fbca-067f28911f4c"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using sklearn with linear kernel"
      ],
      "metadata": {
        "id": "EmhsJjH92h9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting the model with training data\n",
        "\n",
        "poly1 = OneVsRestClassifier(svm.SVC(kernel='linear', degree=3, C=1))\n",
        "\n",
        "poly1.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Making a prediction on the test set\n",
        "prediction1 = poly1.predict(X_test)\n",
        "   \n",
        "# Evaluating the model\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, prediction1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bODZecjX2kPp",
        "outputId": "4f6dbc7b-85b7-44ac-cb7b-07804b78bf14"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Multi-class_SVM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "33b4dd74dfcd88eb53028e19ebcfc18a14279eb6fccfcf244dc9ddab920fb54f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}